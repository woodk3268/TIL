
# 🧠 계산 그래프와 역전파

---

## ✅ 학습 주제

* 계산 그래프의 구성 요소 (덧셈, 곱셈 노드 등)
* 시그모이드와 Affine 계층의 순전파/역전파
* 기울기 소실과 포화 현상
* 모멘텀 최적화, 가중치 초기화, 뉴런 구조 이해

---

## 🧩 핵심 개념 요약

| 개념             | 설명                                                                                |
| -------------- | --------------------------------------------------------------------------------- |
| 덧셈 노드          | 입력값을 단순히 더함. 역전파 시, 각 입력에 동일한 기울기 전달                                              |
| 곱셈 노드          | 입력값을 곱함. 역전파 시, **서로의 순전파 입력값**이 필요함                                              |
| Affine 계층      | $z = Wx + b$. 선형 변환 계층. 역전파 시 $\frac{dL}{dW}, \frac{dL}{db}, \frac{dL}{dx}$ 모두 계산 |
| 시그모이드 함수       | $\sigma(x) = \frac{1}{1 + e^{-x}}$. 출력이 0\~1. 도함수는 $\sigma(x)(1 - \sigma(x))$     |
| 포화 현상          | 시그모이드 출력이 0 또는 1에 가까울 때, 기울기가 거의 0이 되는 현상                                         |
| 기울기 소실         | 역전파 중 기울기가 점점 작아져 앞층까지 전달되지 않는 현상                                                 |
| 모멘텀            | 이전 이동 방향을 반영해 진동을 줄이고 빠르게 수렴하도록 하는 최적화 기법                                         |
| 뉴런             | 여러 입력을 받아 가중합을 계산하고 비선형 함수를 통과시켜 하나의 출력을 생성하는 단위                                  |
| 활성화 값          | 각 층에서 비선형 함수를 통과한 결과 값 (post-activation)                                          |
| pre-activation | 비선형 함수 적용 전의 선형 결합 결과 값 ($Wx + b$)                                                |

---

## 🔄 순전파 / 역전파 예시

### ▶︎ Affine 계층

```python
# 순전파
z = np.dot(W, x) + b

# 역전파
dL/dx = np.dot(W.T, dL/dz)
dL/dW = np.dot(dL/dz, x.T)
dL/db = np.sum(dL/dz, axis=0)
```

### ▶︎ Sigmoid 계층

```python
# 순전파
a = 1 / (1 + np.exp(-z))

# 역전파
dL/dz = dL/da * a * (1 - a)
```

---

## 📊 시그모이드 포화 영역

| 입력값 $x$ | 출력값 $\sigma(x)$ | 기울기 $\sigma'(x)$ |
| ------- | --------------- | ---------------- |
| -10     | ≈ 0             | ≈ 0              |
| 0       | 0.5             | 0.25 (최대)        |
| +10     | ≈ 1             | ≈ 0              |

* $x$가 ±5를 벗어나면 기울기가 거의 0 ⇒ **기울기 소실 발생**

---

## 🔧 최적화 기법: 모멘텀

$$
v_t = \alpha \cdot v_{t-1} - \eta \cdot \nabla W
$$

$$
W = W + v_t
$$

| 항목       | 의미              |
| -------- | --------------- |
| $v$      | 속도(이전 방향 누적)    |
| $\alpha$ | 모멘텀 계수 (예: 0.9) |
| $\eta$   | 학습률             |
| 장점       | 진동 감소, 수렴 가속    |

---

## 🧠 뉴런 구조 & 예시

### 입력:

$$
x = [나이, 연봉, 경험]
$$

### 뉴런 하나:

$$
z = 0.5 \cdot 나이 + 0.1 \cdot 연봉 + 1.2 \cdot 경험 + b
$$

→ **입력의 중요도를 조정한 후 합산 → 판단값 생성**

---

## 🚨 기울기 소실 vs 폭주 요약

| 문제     | 설명                  | 원인 함수            | 대책                  |
| ------ | ------------------- | ---------------- | ------------------- |
| 기울기 소실 | 앞층으로 갈수록 기울기가 0에 수렴 | Sigmoid, tanh    | ReLU, BN, 초기화       |
| 기울기 폭주 | 앞층으로 갈수록 기울기 커짐     | ReLU 등 + 잘못된 초기화 | Gradient clipping 등 |

---

## 💡 인사이트

* 시그모이드는 출력층에서만 사용하는 게 일반적 (중간층엔 ReLU 계열 권장)
* Affine 계층은 가중치 학습의 핵심이 되는 기본 구조
* 포화 현상은 반드시 시각화로 확인 (히스토그램이나 분포 확인)
* 모멘텀은 진동 억제 + 빠른 수렴이라는 두 가지 효과를 동시에 줌

