# 🧪 모델 튜닝과 확률 분포 기반 탐색

---

## ✅ 학습 주제

* 하이퍼파라미터의 개념과 모델 성능에 미치는 영향
* 그리드 서치와 랜덤 서치의 구조 및 차이
* `scipy.stats` 확률 분포 객체를 활용한 파라미터 샘플링
* RandomizedSearchCV의 실전 적용 방식

---

## 🧩 핵심 개념 요약

| 개념                     | 설명                                                                         |
| ---------------------- | -------------------------------------------------------------------------- |
| **하이퍼파라미터**            | 학습 전에 사람이 설정하는 파라미터. 모델 구조나 학습 전략에 영향을 줌 (예: `learning_rate`, `max_depth`) |
| **모델 튜닝**              | 하이퍼파라미터의 값을 변경해가며 최적의 성능을 찾는 과정                                            |
| **그리드 서치**             | 사람이 지정한 값의 조합을 전부 실험하는 방식                                                  |
| **랜덤 서치**              | 하이퍼파라미터 값을 확률 분포에서 무작위로 뽑아 실험                                              |
| **확률 분포 객체**           | `scipy.stats`에서 제공하는 분포 모델로, 샘플링/밀도계산 가능                                   |
| **RandomizedSearchCV** | 확률 분포 기반의 파라미터 샘플링 + 교차검증 조합으로 튜닝 자동화                                      |

---

## 🔍 하이퍼파라미터란?

* 학습 데이터로부터 **직접 학습되지 않으며**, 사람이 미리 지정
* 일반적으로:

  * 모델 구조에 관한 것 → `max_depth`, `hidden_units`
  * 학습 전략에 관한 것 → `learning_rate`, `batch_size`, `dropout`
* 값 설정이 부정확할 경우 과적합/과소적합 발생 가능

---

## 🔎 그리드 서치 vs 랜덤 서치

| 항목         | 그리드 서치              | 랜덤 서치           |
| ---------- | ------------------- | --------------- |
| 값 탐색 방식    | 미리 정한 조합을 전부 실험     | 분포에서 무작위로 샘플 추출 |
| 탐색 범위      | 좁고 고정적              | 유연하고 넓음         |
| 계산량        | 조합 수 × 교차검증 수 만큼 증가 | `n_iter`로 제어 가능 |
| 연속 파라미터 지원 | 직접 이산화 필요           | 연속 분포 사용 가능     |
| 사용 예시      | 작은 튜닝 공간            | 고차원, 연속값 포함된 상황 |

---

## 🎲 `scipy.stats` 확률 분포 객체

| 분포       | 객체                    | 사용 예                                           |
| -------- | --------------------- | ---------------------------------------------- |
| 균등 분포    | `uniform(loc, scale)` | `learning_rate ∈ [0.01, 0.2]`                  |
| 정수 균등 분포 | `randint(low, high)`  | `max_depth ∈ [3, 10]`                          |
| 로그 균등 분포 | `reciprocal(a, b)`    | `alpha ∈ [1e-5, 1]` 같은 scale-sensitive 하이퍼파라미터 |
| 정규 분포    | `norm(loc, scale)`    | `dropout` 등 중심 중심 기반 샘플링                       |

🔧 주요 메서드:

* `rvs(size=n)` : 난수 샘플링
* `pdf(x)` : 확률 밀도
* `cdf(x)` : 누적 분포
* `mean()`, `var()`: 기대값, 분산

---

## 🛠️ RandomizedSearchCV 실전 예시

```python
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import GradientBoostingClassifier
from scipy.stats import uniform, randint

param_dist = {
    'learning_rate': uniform(0.01, 0.2),     # [0.01, 0.21)
    'max_depth': randint(3, 10),             # {3, 4, ..., 9}
    'n_estimators': randint(50, 300)
}

search = RandomizedSearchCV(
    estimator=GradientBoostingClassifier(),
    param_distributions=param_dist,
    n_iter=50,
    cv=5,
    random_state=42
)
search.fit(X_train, y_train)
```

🧠 이 방식의 장점:

* `learning_rate` 같은 연속 파라미터를 부드럽게 샘플링 가능
* 자원 소모를 `n_iter`로 제어 가능
* 확률적이지만, **초기 실험 단계에서 훨씬 효율적**

---

## 🧠 실무 활용 팁

| 상황              | 추천 접근                                        |
| --------------- | -------------------------------------------- |
| 파라미터 후보가 명확한 경우 | Grid Search (초기 성능 확인용)                      |
| 연속형 파라미터 포함된 경우 | RandomizedSearchCV + `uniform`, `reciprocal` |
| 성능 민감한 파라미터     | 로그 스케일 분포 사용 (`reciprocal`)                  |
| 대규모 탐색 필요 시     | Optuna 등 고급 AutoML 프레임워크 활용 권장               |

---

## 💡 인사이트

* 하이퍼파라미터 튜닝은 단순 반복이 아니라 **확률적 탐색과 분포 설계**의 싸움이다.
* `scipy.stats` 분포 객체를 이해하면 **랜덤 서치의 범위를 정밀하게 제어**할 수 있다.
* **성능 최적화의 시작은 좋은 탐색 전략 설계**에 달려 있다.

